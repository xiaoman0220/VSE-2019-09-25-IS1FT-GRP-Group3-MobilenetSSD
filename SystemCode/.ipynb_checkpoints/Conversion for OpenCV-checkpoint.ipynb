{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1 shape:  (?, 150, 150, 64)\n",
      "conv3 shape:  (?, 75, 75, 128)\n",
      "conv5 shape:  (?, 38, 38, 256)\n",
      "conv11 shape:  (?, 19, 19, 512)\n",
      "conv13 shape:  (?, 10, 10, 1024)\n",
      "conv14 shape (?, 5, 5, 512)\n",
      "conv15 shape (?, 3, 3, 256)\n",
      "conv16 shape (?, 2, 2, 256)\n",
      "conv17 shape (?, 1, 1, 128)\n",
      "in training mode\n",
      "Tensor(\"input_2:0\", shape=(?, 300, 300, 3), dtype=float32) [<tf.Tensor 'predictions_1/concat:0' shape=(?, ?, 19) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../SystemCode\")\n",
    "import numpy as np\n",
    "from keras import applications\n",
    "from keras import backend as K\n",
    "import cv2 as cv\n",
    "import tensorflow as tf\n",
    "from ssd300 import ssd_mobilenet\n",
    "\n",
    "K.set_learning_phase(0)\n",
    "img_height = 300  # Height of the input images\n",
    "img_width = 300  # Width of the input images\n",
    "img_channels = 3  # Number of color channels of the input images\n",
    "subtract_mean = [123, 117, 104]  # The per-channel mean of the images in the dataset\n",
    "swap_channels = True  # The color channel order in the original SSD is BGR\n",
    "n_classes = 6  # Number of positive classes, e.g. 20 for Pascal VOC, 80 for MS COCO\n",
    "scales_voc = [0.1, 0.2, 0.37, 0.54, 0.71, 0.88,\n",
    "              1.05]  # The anchor box scaling factors used in the original SSD300 for the Pascal VOC datasets\n",
    "scales_coco = [0.07, 0.15, 0.33, 0.51, 0.69, 0.87,\n",
    "               1.05]  # The anchor box scaling factors used in the original SSD300 for the MS COCO datasets\n",
    "scales = scales_voc\n",
    "\n",
    "aspect_ratios = [[1.0, 2.0, 0.5],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0 / 3.0],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0 / 3.0],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0 / 3.0],\n",
    "                 [1.0, 2.0, 0.5],\n",
    "                 [1.0, 2.0, 0.5]]  # The anchor box aspect ratios used in the original SSD300; the order matters\n",
    "two_boxes_for_ar1 = True\n",
    "steps = [8, 16, 32, 64, 100, 300]  # The space between two adjacent anchor box center points for each predictor layer.\n",
    "offsets = [0.5, 0.5, 0.5, 0.5, 0.5,\n",
    "           0.5]  # The offsets of the first anchor box center points from the top and left borders of the image as a fraction of the step size for each predictor layer.\n",
    "limit_boxes = False  # Whether or not you want to limit the anchor boxes to lie entirely within the image boundaries\n",
    "variances = [0.1, 0.1, 0.2,\n",
    "             0.2]  # The variances by which the encoded target coordinates are scaled as in the original implementation\n",
    "coords = 'centroids'  # Whether the box coordinates to be used as targets for the model should be in the 'centroids', 'corners', or 'minmax' format, see documentation\n",
    "normalize_coords = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "classes = ['background','Player', 'Gun', 'Vehicle', 'House', 'Tree', 'Plane']\n",
    "\n",
    "# 1: Build the Keras model\n",
    "\n",
    "# K.clear_session()  # Clear previous models from memory.\n",
    "\n",
    "model = ssd_mobilenet.ssd_300(\"training\",\n",
    "                image_size=(img_height, img_width, img_channels),\n",
    "                n_classes=n_classes,\n",
    "                l2_regularization=0.0005,\n",
    "                scales=scales,\n",
    "                aspect_ratios_per_layer=aspect_ratios,\n",
    "                two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                steps=steps,\n",
    "                offsets=offsets,\n",
    "                limit_boxes=limit_boxes,\n",
    "                variances=variances,\n",
    "                coords=coords,\n",
    "                normalize_coords=normalize_coords,\n",
    "                subtract_mean=subtract_mean,\n",
    "                divide_by_stddev=127.5,\n",
    "                swap_channels=swap_channels)\n",
    "\n",
    "\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.name = layer.name + \"_v1\"\n",
    "\n",
    "model.load_weights(\"../Miscellaneous/checkpoints/ssd300_epoch-200.h5\")\n",
    "\n",
    "sess = K.get_session()\n",
    "\n",
    "print(model.input, model.outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.tools import freeze_graph\n",
    "from tensorflow.python.tools import optimize_for_inference_lib\n",
    "\n",
    "MODEL_PATH = '../Miscellaneous/out'\n",
    "MODEL_NAME = 'test'\n",
    "input_node_name = 'input_8'\n",
    "output_node_name = 'predictions_7/concat'\n",
    "!rm -rf {MODEL_PATH}/\n",
    "\n",
    "tf.train.write_graph(sess.graph_def, MODEL_PATH, 'test_graph.pb', as_text=False)\n",
    "tf.train.write_graph(sess.graph_def, MODEL_PATH, 'test_graph.pbtxt')\n",
    "tf.train.Saver().save(sess, MODEL_PATH+'/test.chkp')\n",
    "\n",
    "freeze_graph.freeze_graph(MODEL_PATH+'/test_graph.pbtxt',\n",
    "                          None, False,\n",
    "                          MODEL_PATH+'/test.chkp',\n",
    "                          output_node_name,\n",
    "                          \"save/restore_all\",\n",
    "                          \"save/Const:0\",\n",
    "                          MODEL_PATH+\"/frozen_test.pb\",\n",
    "                          True, \"\")\n",
    "\n",
    "graph_def = tf.GraphDef()\n",
    "with tf.gfile.Open(MODEL_PATH+\"/frozen_test.pb\", \"rb\") as f:\n",
    "    graph_def.ParseFromString(f.read())\n",
    "\n",
    "output_graph_def = optimize_for_inference_lib.optimize_for_inference(\n",
    "    graph_def, [input_node_name], [output_node_name], tf.float32.as_datatype_enum)\n",
    "\n",
    "with tf.gfile.GFile(MODEL_PATH+'/opt_test.pb', \"wb\") as f:\n",
    "    f.write(output_graph_def.SerializeToString())\n",
    "\n",
    "# Strip Const nodes.\n",
    "for i in reversed(range(len(graph_def.node))):\n",
    "    if graph_def.node[i].op == 'Const':\n",
    "        del graph_def.node[i]\n",
    "\n",
    "# Save stripped model.\n",
    "tf.train.write_graph(graph_def, \"\", MODEL_PATH+'/stripped_test.pbtxt', as_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.1) /io/opencv/modules/dnn/src/tensorflow/tf_importer.cpp:582: error: (-2:Unspecified error) Input [conv0/bn_5/gamma] for node [conv0/bn_5/FusedBatchNorm_1] not found in function 'getConstBlob'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-496ef7a8c80d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadNetFromTensorflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/opt_test.pb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/stripped_test.pbtxt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.1.1) /io/opencv/modules/dnn/src/tensorflow/tf_importer.cpp:582: error: (-2:Unspecified error) Input [conv0/bn_5/gamma] for node [conv0/bn_5/FusedBatchNorm_1] not found in function 'getConstBlob'\n"
     ]
    }
   ],
   "source": [
    "net = cv.dnn.readNetFromTensorflow(MODEL_PATH+'/opt_test.pb', MODEL_PATH+'/stripped_test.pbtxt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.tools.graph_transforms import TransformGraph\n",
    "def optimize_graph(model_dir, graph_filename, transforms, output_names, outname='optimized_model.pb'):\n",
    "    input_names = ['input_image',] # change this as per how you have saved the model\n",
    "    graph_def = get_graph_def_from_file(os.path.join(model_dir, graph_filename))\n",
    "    optimized_graph_def = TransformGraph(\n",
    "      graph_def,\n",
    "      input_names,  \n",
    "      output_names,\n",
    "      transforms)\n",
    "    tf.train.write_graph(optimized_graph_def,\n",
    "                      logdir=model_dir,\n",
    "                      as_text=False,\n",
    "                      name=outname)\n",
    "    print('Graph optimized!')\n",
    "\n",
    "optimize_graph()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
